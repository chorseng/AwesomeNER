{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go through a CRF only named-entity recognition implementation based on finance corpus. The following would be the sequence of the notebook:\n",
    "<br>\n",
    "1. Loading the dataset into a dataframe\n",
    "2. Data Preprocessing\n",
    "3. Extract features from the sentences (Feature Engineering)\n",
    "4. Training a Condtional Random Field model\n",
    "5. Evaluating the trained CRF model\n",
    "6. Optimising the hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pyprind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-1b360a514c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyprind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pyprind'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pyprind\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.exceptions import UndefinedMetricWarning \n",
    "\n",
    "import warnings\n",
    "import nltk\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, the data is loaded into a Pandas DataFrame. This can be done easily using the read_csv function, specifying that the separator is a space. It's also useful to keep the blank lines, which are helpful later for determining the sentence breaks. <br>\n",
    "<br>\n",
    "Once the data is loaded into a DataFrame, the easy access we have to columns allows a couple of useful things to be done - group the data by the \"ne\" column to see the distributions of each tag, and extract the classes (disregarding 'O' and blank lines with NaN values) as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech Tag Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Token                    NE  POS\n",
      "0   $2,000,000     B-Notional Amount   CD\n",
      "1          USD     I-Notional Amount  NNP\n",
      "2    6/20/2011     B-Expiration Date   CD\n",
      "3    Agreement                     O  NNP\n",
      "4         with                     O   IN\n",
      "5           JP        B-Counterparty  NNP\n",
      "6       Morgan        I-Counterparty  NNP\n",
      "7        dated                     O  VBD\n",
      "8      6/17/06                     O   CD\n",
      "9      whereby                     O   IN\n",
      "10         the                     O   DT\n",
      "11   Portfolio                     O  NNP\n",
      "12        will                     O   MD\n",
      "13     receive  B-Direction of Trade   VB\n",
      "14       0.35%          B-Fixed Rate   CD\n",
      "15         per                     O   IN\n",
      "16   yeartimes                     O  NNS\n",
      "17         the                     O   DT\n",
      "18    notional                     O   JJ\n",
      "19  amount.The                     O   NN\n",
      "20   Portfolio                     O  NNP\n",
      "21       makes                     O  VBZ\n",
      "22           a                     O   DT\n",
      "23     payment                     O   NN\n",
      "24        only                     O   RB\n",
      "25        upon                     O   IN\n",
      "26           a                     O   DT\n",
      "27     default                     O   NN\n",
      "28       event                     O   NN\n",
      "29          on                     O   IN\n",
      "..         ...                   ...  ...\n",
      "45       dated                     O  VBD\n",
      "46     6/17/06                     O   CD\n",
      "47     whereby                     O   IN\n",
      "48         the                     O   DT\n",
      "49   Portfolio                     O  NNP\n",
      "50        will                     O   MD\n",
      "51         pay  B-Direction of Trade   VB\n",
      "52      0.095%          B-Fixed Rate   CD\n",
      "53         per                     O   IN\n",
      "54        year                     O   NN\n",
      "55       times                     O  VBZ\n",
      "56         the                     O   DT\n",
      "57    notional                     O   JJ\n",
      "58  amount.The                     O   NN\n",
      "59   Portfolio                     O  NNP\n",
      "60    receives                     O  VBZ\n",
      "61           a                     O   DT\n",
      "62     payment                     O   NN\n",
      "63        only                     O   RB\n",
      "64        upon                     O   IN\n",
      "65           a                     O   DT\n",
      "66     default                     O   NN\n",
      "67       event                     O   NN\n",
      "68          on                     O   IN\n",
      "69         the                     O   DT\n",
      "70   reference                     O   NN\n",
      "71     entity,                     O   NN\n",
      "72        HSBC    B-Reference Entity  NNP\n",
      "73       Bank,    I-Reference Entity  NNP\n",
      "74         PLC    I-Reference Entity  NNP\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the NER data keeping blank lines and adding columns\n",
    "ner_data = pd.read_csv(\"../Data/tag1.csv\", skip_blank_lines=False, encoding=\"utf-8\", index_col=None)\n",
    "ner_data.columns = [\"Token\", \"NE\"]\n",
    "\n",
    "POS_tags =  nltk.pos_tag(ner_data[\"Token\"])\n",
    "POS_List = []\n",
    "\n",
    "for w in POS_tags:\n",
    "    POS_List.append(w[1])\n",
    "    \n",
    "ner_data[\"POS\"] = POS_List\n",
    "    \n",
    "print(ner_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Tag Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     NE  counts\n",
      "0        B-Counterparty       2\n",
      "1  B-Direction of Trade       2\n",
      "2     B-Expiration Date       2\n",
      "3          B-Fixed Rate       2\n",
      "4     B-Notional Amount       2\n",
      "5    B-Reference Entity       2\n",
      "6        I-Counterparty       2\n",
      "7     I-Notional Amount       1\n",
      "8    I-Reference Entity       5\n",
      "9                     O      55\n"
     ]
    }
   ],
   "source": [
    "tag_distribution = ner_data.groupby(\"NE\").size().reset_index(name='counts')\n",
    "print(tag_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filtering the classes of Named Entity that we do not require in this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Notional Amount', 'I-Notional Amount', 'B-Expiration Date', 'B-Counterparty', 'I-Counterparty', 'B-Direction of Trade', 'B-Fixed Rate', 'B-Reference Entity', 'I-Reference Entity']\n"
     ]
    }
   ],
   "source": [
    "classes = list(filter(lambda x: x not in [\"O\", np.nan], list(ner_data[\"NE\"].unique())))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from the sentences (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Create a sentences dictionary and an initial single sentence dictionary\n",
    "sentences, sentence = [], []\n",
    "# Create a progress bar\n",
    "# pbar = pyprind.ProgBar(len(ner_data))\n",
    "# For each row in the NER data...\n",
    "for index, row in ner_data.iterrows():\n",
    "    # If the row is empty (no string in the token column)\n",
    "    if type(row[\"Token\"]) != str:\n",
    "        # If the current sentence is not empty, append it to the sentences and create a new sentence\n",
    "        if len(sentence) > 0:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "    # Otherwise...\n",
    "    else:\n",
    "        # If the row does not indicate the start of a document, add the token to the current sentence\n",
    "        if type(row[\"Token\"]) != float and type(row[\"POS\"]) != float and type(row[\"NE\"]) != float:\n",
    "            if not row[\"Token\"].startswith(\"-DOCSTART-\"):\n",
    "                sentence.append([row[\"Token\"], row[\"POS\"], row[\"NE\"]])\n",
    "    #pbar.update()\n",
    "print (\"Done\")\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner",
   "language": "python",
   "name": "ner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
