{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go through a CRF only named-entity recognition implementation based on finance corpus. The following would be the sequence of the notebook:\n",
    "<br>\n",
    "1. Data Preprocessing\n",
    "2. Extract features from the sentences (Feature Engineering)\n",
    "3. Training a Condtional Random Field model\n",
    "4. Evaluating the trained CRF model\n",
    "5. Optimising the hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.exceptions import UndefinedMetricWarning \n",
    "\n",
    "import warnings\n",
    "import nltk\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, the data is loaded into a Pandas DataFrame. This can be done easily using the read_csv function, specifying that the separator is a space. It's also useful to keep the blank lines, which are helpful later for determining the sentence breaks. <br>\n",
    "<br>\n",
    "Once the data is loaded into a DataFrame, the easy access we have to columns allows a couple of useful things to be done - group the data by the \"ne\" column to see the distributions of each tag, and extract the classes (disregarding 'O' and blank lines with NaN values) as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech Tag Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Token                    NE   POS\n",
      "0    $2,000,000     B-Notional Amount    CD\n",
      "1           USD     I-Notional Amount   NNP\n",
      "2     6/20/2011     B-Expiration Date    CD\n",
      "3     Agreement                     O   NNP\n",
      "4          with                     O    IN\n",
      "5            JP        B-Counterparty   NNP\n",
      "6        Morgan        I-Counterparty   NNP\n",
      "7         dated                     O   VBD\n",
      "8       6/17/06                     O    CD\n",
      "9       whereby                     O    IN\n",
      "10          the                     O    DT\n",
      "11    Portfolio                     O   NNP\n",
      "12         will                     O    MD\n",
      "13      receive  B-Direction of Trade    VB\n",
      "14        0.35%          B-Fixed Rate    CD\n",
      "15          per                     O    IN\n",
      "16    yeartimes                     O   NNS\n",
      "17          the                     O    DT\n",
      "18     notional                     O    JJ\n",
      "19      amount.                     O    NN\n",
      "20           \\\\                   NaN   VBD\n",
      "21          The                   NaN    DT\n",
      "22    Portfolio                     O   NNP\n",
      "23        makes                     O   VBZ\n",
      "24            a                     O    DT\n",
      "25      payment                     O    NN\n",
      "26         only                     O    RB\n",
      "27         upon                     O    IN\n",
      "28            a                     O    DT\n",
      "29      default                     O    NN\n",
      "..          ...                   ...   ...\n",
      "580       event                     O    NN\n",
      "581          of                     O    IN\n",
      "582       MASTR    B-Reference Entity   NNP\n",
      "583       Asset    I-Reference Entity   NNP\n",
      "584      Backed    I-Reference Entity   NNP\n",
      "585  Securities    I-Reference Entity  NNPS\n",
      "586      Trust,    I-Reference Entity   NNP\n",
      "587         par                     O    IN\n",
      "588       value                     O    NN\n",
      "589          of                     O    IN\n",
      "590         the                     O    DT\n",
      "591    notional                     O    JJ\n",
      "592      amount                     O    NN\n",
      "593          of                     O    IN\n",
      "594       MASTR                     O   NNP\n",
      "595       Asset                     O   NNP\n",
      "596      Backed                     O   NNP\n",
      "597  Securities                     O  NNPS\n",
      "598       Trust                     O   NNP\n",
      "599      Series                     O   NNP\n",
      "600    2003.NC1                     O    CD\n",
      "601       Class                     O   NNP\n",
      "602         M6,                     O   NNP\n",
      "603     8.1913%                     O    CD\n",
      "604     4/25/33                     O    CD\n",
      "605         May     B-Expiration Date   NNP\n",
      "606        2033     I-Expiration Date    CD\n",
      "607      569000     B-Notional Amount    CD\n",
      "608      169038                     O    CD\n",
      "609          \\\\                   NaN    NN\n",
      "\n",
      "[688 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the NER data keeping blank lines and adding columns\n",
    "ner_data = pd.concat([pd.read_csv(f, skip_blank_lines=False, encoding=\"utf-8\", index_col=None) for f in glob.glob(\"../Data/*.csv\")])\n",
    "ner_data.columns = [\"Token\", \"NE\"]\n",
    "\n",
    "POS_tags =  nltk.pos_tag(ner_data[\"Token\"])\n",
    "POS_List = []\n",
    "\n",
    "for w in POS_tags:\n",
    "    POS_List.append(w[1])\n",
    "    \n",
    "ner_data[\"POS\"] = POS_List\n",
    "    \n",
    "print(ner_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Tag Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NE  counts\n",
      "0         B-Counterparty      16\n",
      "1   B-Direction of Trade      16\n",
      "2      B-Expiration Date      16\n",
      "3           B-Fixed Rate      16\n",
      "4      B-Notional Amount      16\n",
      "5     B-Reference Entity      16\n",
      "6         I-Counterparty      18\n",
      "7      I-Expiration Date      14\n",
      "8      I-Notional Amount       1\n",
      "9     I-Reference Entity      64\n",
      "10                     O     478\n"
     ]
    }
   ],
   "source": [
    "tag_distribution = ner_data.groupby(\"NE\").size().reset_index(name='counts')\n",
    "print(tag_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filtering the classes of Named Entity that we do not require in this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Notional Amount', 'I-Notional Amount', 'B-Expiration Date', 'B-Counterparty', 'I-Counterparty', 'B-Direction of Trade', 'B-Fixed Rate', 'B-Reference Entity', 'I-Reference Entity', 'I-Expiration Date']\n"
     ]
    }
   ],
   "source": [
    "classes = list(filter(lambda x: x not in [\"O\", np.nan], list(ner_data[\"NE\"].unique())))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sentences from dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, sentences need to be extracted from the data - it's useful to have the sentences as a list of lists, with each sublist containing the token, POS tag, and NE label for every word token in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sentences dictionary and an initial single sentence dictionary\n",
    "sentences, sentence = [], []\n",
    "# Create a progress bar\n",
    "# pbar = pyprind.ProgBar(len(ner_data))\n",
    "# For each row in the NER data...\n",
    "for index, row in ner_data.iterrows():\n",
    "    # If the row is empty (no string in the token column)\n",
    "    if '\\\\' in row[\"Token\"]:\n",
    "        # If the current sentence is not empty, append it to the sentences and create a new sentence\n",
    "        if len(sentence) > 0:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "    # Otherwise...\n",
    "    else:\n",
    "        # If the row does not indicate the start of a document, add the token to the current sentence\n",
    "        if type(row[\"Token\"]) != float and type(row[\"POS\"]) != float and type(row[\"NE\"]) != float:\n",
    "            sentence.append([row[\"Token\"], row[\"POS\"], row[\"NE\"]])\n",
    "    #pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define a function which would allow us to extract the word features in the sentence. This includes the following:\n",
    "<br>\n",
    "1. Current Parts of Speech Tags\n",
    "2. Previous and Next Parts of Speech Tags\n",
    "3. Current Words\n",
    "4. Previous Words\n",
    "5. Next Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>For now, we have avoided chunking however a little internet research shows us that chunking indeed can improve the accuracy and sensitivity of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWordFeatures(sentence, iterator):\n",
    "    POS = sentence[iterator][1]\n",
    "    Token = sentence[iterator][0]\n",
    "\n",
    "    # Aggregating a feuature dicitonary based on the features of the current POS and word\n",
    "    \n",
    "    featureDict = { \"POS[:2]\" : POS[:2],\n",
    "                 \"POS\" : POS,\n",
    "                 \"Token.isdigit()\" : Token.isdigit(),\n",
    "                 \"Token.istitle()\" : Token.istitle(),\n",
    "                 \"Token.isupper()\" : Token.isupper(),\n",
    "                 \"Token[-2:]\" : Token[-2:],\n",
    "                 \"Token[-3:]\" : Token[-3:],\n",
    "                 \"Token.lower()\" : Token.lower(),\n",
    "                 \"bias\" : 1.0,\n",
    "    }\n",
    "    \n",
    "    if iterator > 1:\n",
    "        previousWord = sentence[iterator-1][0]\n",
    "        previousPosTag = sentence[iterator-1][1]\n",
    "        \n",
    "        # Add characteristics of the sentence's previous word and POS to the feature dictionary\n",
    "        featureDict.update({ \"-1:Token.lower()\": previousWord.lower(),\n",
    "                          \"-1:Token.istitle()\": previousWord.istitle(),\n",
    "                          \"-1:Token.isupper()\": previousWord.isupper(),\n",
    "                          \"-1:POS\": previousPosTag,\n",
    "                          \"-1:POS[:2]\": previousPosTag[:2],\n",
    "                        })\n",
    "        \n",
    "    # Add \"Beginning of Sentence\" at the start of the dictionary    \n",
    "    else:\n",
    "        featureDict[\"BOS\"] = True\n",
    "    \n",
    "    if iterator < len(sentence)-1:\n",
    "        nextWord = sentence[iterator+1][0]\n",
    "        nextPos = sentence[iterator+1][1]\n",
    "        # Add characteristics of the sentence's previous next and POS to the feature dictionary\n",
    "        featureDict.update({ \"+1:Token.lower()\": nextWord.lower(),\n",
    "                          \"+1:Token.istitle()\": nextWord.istitle(),\n",
    "                          \"+1:Token.isupper()\": nextWord.isupper(),\n",
    "                          \"+1:POS\": nextPos,\n",
    "                          \"+1:POS[:2]\": nextPos[:2],\n",
    "                        })\n",
    "        \n",
    "    else:\n",
    "        featureDict[\"EOS\"] = True\n",
    "    \n",
    "    return featureDict    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the word_features function, a list of feature dictionaries for each word token in a sentence can be extracted, corresponding to a list of NE labels for each word token in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a feature dictionary for each word in a given sentence\n",
    "def sentence_features(sentence):\n",
    "    return [extractWordFeatures(sentence, iterator) for iterator in range(len(sentence))]\n",
    "\n",
    "# Return the label (NER tag) for each word in a given sentence\n",
    "def sentence_labels(sentence):\n",
    "    return [label for token, pos, label in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Condtional Random Field model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the predefined functions, X and y can be extracted as lists of feature dictionaries for each word token in each sentence, and as lists of NE labels for each word token in each sentence, respectively. scikit-learn's 'test_train_split' function can then be used to split X and y into training and test sets, split 80% training to 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First token features:\n",
      "---------------------\n",
      "{'+1:Token.lower()': 'monthly', 'Token.istitle()': True, 'POS': 'NNP', 'Token.lower()': 'receive', '+1:POS[:2]': 'RB', '+1:POS': 'RB', 'Token[-3:]': 'ive', 'Token.isupper()': False, 'POS[:2]': 'NN', '+1:Token.isupper()': False, '+1:Token.istitle()': False, 'BOS': True, 'Token.isdigit()': False, 'bias': 1.0, 'Token[-2:]': 've'}\n",
      "\n",
      "First token label:\n",
      "------------------\n",
      "B-Direction of Trade\n"
     ]
    }
   ],
   "source": [
    "# For each sentence, extract the sentence features as X, and the labels as y\n",
    "X = [sentence_features(sentence) for sentence in sentences]\n",
    "y = [sentence_labels(sentence) for sentence in sentences]\n",
    "\n",
    "# Split X and y into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"First token features:\\n{}\\n{}\".format(\"-\"*21, X_train[0][0]))\n",
    "print(\"\\nFirst token label:\\n{}\\n{}\".format(\"-\"*18, y_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new CRF model\n",
    "crf = CRF(algorithm=\"lbfgs\",\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=True)\n",
    "\n",
    "# Train the CRF model on the supplied training data\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "   B-Notional Amount       1.00      0.75      0.86         4\n",
      "   I-Notional Amount       0.00      0.00      0.00         0\n",
      "   B-Expiration Date       1.00      0.75      0.86         4\n",
      "      B-Counterparty       1.00      1.00      1.00         3\n",
      "      I-Counterparty       1.00      1.00      1.00         2\n",
      "B-Direction of Trade       1.00      1.00      1.00         3\n",
      "        B-Fixed Rate       1.00      1.00      1.00         3\n",
      "  B-Reference Entity       1.00      0.75      0.86         4\n",
      "  I-Reference Entity       1.00      0.81      0.90        16\n",
      "   I-Expiration Date       1.00      1.00      1.00         3\n",
      "\n",
      "           micro avg       1.00      0.86      0.92        42\n",
      "           macro avg       0.90      0.81      0.85        42\n",
      "        weighted avg       1.00      0.86      0.92        42\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvsaripalli/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vvsaripalli/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Use the CRF model to make predictions on the test data\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner",
   "language": "python",
   "name": "ner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
